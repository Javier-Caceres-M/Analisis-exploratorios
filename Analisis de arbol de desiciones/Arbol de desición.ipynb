{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo prectivos de precios de inmuebles\n",
    "\n",
    "Para esta sesión trabajaremos con una base de datos sobre los precios de inmuebles en la ciudad de Ames, Iowa. La base se compone de 2930 registros y contiene un gran número de atributos.\n",
    "\n",
    "Nuestro objetivo es generar un modelo que prediga de forma adecuada los precios de inmuebles, medidos con la variable `S​ale_Price​`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del ambiente de trabajo\n",
    "\n",
    "- Se importan las librerías clásicas a utilizar.\n",
    "- Para este ejercicio implementaremos árboles de regresión, por lo que deberá importar la clase ​DecisionTreeRegressor​.\n",
    "- De manera adicional importe las funciones y clases necesarias para generar un desempeño de métricas en problemas de regresión, división de muestras y búsqueda de grilla con validación cruzada.\n",
    "- Se eliminan la columna 'Unnamed: 0' cuando cargue los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv('ames_housing.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "- Se identifica si el `​dtype` de cada `​pd.Serie` en nuestra base de datos se considera `'object'`​ o no. Para todas las variables que sean `​'object'`​, realice lo siguiente:\n",
    "    + Se generan una recodificación $k − 1$ en cada variable. Para efectos prácticos sólo necesitan eliminar una de las categorías, no se concentren en especificar la categoría a eliminar. Pueden utilizar la función con la opción `​drop_first` para ello.\n",
    "    + Utilizando el método `​pd.concat`​, concatene a los atributos creados en la base de datos.\n",
    "  \n",
    "> **Tip:** No se olvide de eliminar los atributos recodificados, de esta forma evitará un aumento artificial del desempeño del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objeto = df.select_dtypes(include='object')\n",
    "df_codificado = pd.get_dummies(df_objeto, drop_first=True)\n",
    "df = pd.concat([df, df_codificado], axis=1)\n",
    "df = df.drop(columns=df_objeto.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer modelo\n",
    "\n",
    "- Se generan muestras de entrenamiento y validación con `​'Sale_Price'` como vector objetivo y los atributos de la base de datos como matriz.\n",
    "- Recuerde definir el porcentaje de casos en la muestra de validación y una semilla pseudoaleatoria.\n",
    "- Posteriormente, entrene un árbol de regresión en la muestra de entrenamiento sin modificar los hiper parámetros. Reporte las principales métricas de desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE entrenamiento: 0.0\n",
      "R^2 entrenamiento: 1.0\n",
      "RMSE validación: 46277.64255922713\n",
      "R^2 validación: 0.7328833928658394\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns='Sale_Price')\n",
    "y = df['Sale_Price']\n",
    "\n",
    "X_entrenamiento, X_validacion, y_entrenamiento, y_validacion = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "arbol_regresion = DecisionTreeRegressor(random_state=42)\n",
    "arbol_regresion.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "y_entrenamiento_pred = arbol_regresion.predict(X_entrenamiento)\n",
    "y_validacion_pred = arbol_regresion.predict(X_validacion)\n",
    "\n",
    "\n",
    "rmse_entrenamiento = mean_squared_error(y_entrenamiento, y_entrenamiento_pred, squared=False)\n",
    "r2_entrenamiento = r2_score(y_entrenamiento, y_entrenamiento_pred)\n",
    "rmse_validacion = mean_squared_error(y_validacion, y_validacion_pred, squared=False)\n",
    "r2_validacion = r2_score(y_validacion, y_validacion_pred)\n",
    "\n",
    "\n",
    "print(\"RMSE validación:\", rmse_validacion)\n",
    "print(\"R^2 validación:\", r2_validacion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia relativa\n",
    "\n",
    "- Se implementa el método `​plot_importance` utilizado en la lectura para reportar la importancia relativa de los atributos.\n",
    "- Comente sobre cuáles son los principales 10 atributos que afectan la predicción de `Sale_Price​`.\n",
    "- Se separan estos 10 atributos en una nueva base de datos, junto con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 características:\n",
      "Garage_Cars           0.368422\n",
      "Gr_Liv_Area           0.200890\n",
      "Total_Bsmt_SF         0.089019\n",
      "Exter_Qual_Typical    0.063321\n",
      "First_Flr_SF          0.041396\n",
      "Year_Built            0.026110\n",
      "Second_Flr_SF         0.022622\n",
      "Longitude             0.016146\n",
      "Wood_Deck_SF          0.013967\n",
      "Lot_Area              0.011798\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importancia = pd.Series(arbol_regresion.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "top_10_caracteristicas = importancia.head(10)\n",
    "print(\"Top 10 características:\")\n",
    "print(top_10_caracteristicas)\n",
    "df_top_10 = pd.concat([X[top_10_caracteristicas.index], y], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactorización del modelo y `picklingpd.get_dummies`\n",
    "\n",
    "- En función de los atributos seleccionados en el ejercicio anterior, vuelva a generar conjuntos de entrenamiento y validación.\n",
    "- **Dentro de los datos de entrenamiento** genere una búsqueda de grilla con `​GridSearchCV` utilizando los siguientes hiper parámetros:\n",
    "    + **Máximo de atributos**:​ Evalúe todos los posibles atributos.\n",
    "    + **Máximo de profundidad**:​ Entre 1 a 32.\n",
    "    + **Validaciones cruzadas**:​ 5.\n",
    "- Reporte la mejor combinación de hiper parámetros y su desempeño asociado. Compare el desempeño en la muestra de validación con el modelo por defecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 9, 'max_features': 5}\n",
      "Mejor puntaje: 0.7739433918795686\n",
      "RMSE validación (top 10 atributos): 43973.20655787965\n",
      "R^2 validación (top10 atributos): 0.7588236563541169\n"
     ]
    }
   ],
   "source": [
    "X_top_10 = df_top_10.drop(columns='Sale_Price')\n",
    "y_top_10 = df_top_10['Sale_Price']\n",
    "X_train_top_10, X_val_top_10, y_train_top_10, y_val_top_10 = train_test_split(X_top_10, y_top_10, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'max_features': list(range(1, len(X_train_top_10.columns)+1)),\n",
    "    'max_depth': list(range(1, 33))\n",
    "}\n",
    "grid_search = GridSearchCV(arbol_regresion, param_grid, cv=5)\n",
    "grid_search.fit(X_train_top_10, y_train_top_10)\n",
    "mejores_parametros = grid_search.best_params_\n",
    "mejor_puntaje = grid_search.best_score_\n",
    "val_rmse_top_10 = mean_squared_error(y_val_top_10, grid_search.predict(X_val_top_10), squared=False)\n",
    "val_r2_top_10 = r2_score(y_val_top_10, grid_search.predict(X_val_top_10))\n",
    "\n",
    "print(\"Mejores parámetros:\", mejores_parametros)\n",
    "print(\"Mejor puntaje:\", mejor_puntaje)\n",
    "print(\"RMSE validación (top 10 atributos):\", val_rmse_top_10)\n",
    "print(\"R^2 validación (top10 atributos):\", val_r2_top_10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling\n",
    "\n",
    "- Ahora generamos una serialización de nuestro modelo depurado, y nuestros conjuntos de entrenamiento y validación depurados. Para ello importe el módulo `​pickle​`.\n",
    "- `pickle` contiene la función dump, que permite guardar el modelo desarrollado. La forma canónica para desarrollar el pickling es:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "pickle.dump(<OBJETO_CON_EL_MODELO>, open('06-22_nombre-apellido-.sav','wb'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "pickle.dump((grid_search, X_train_top_10, X_val_top_10, y_train_top_10, y_val_top_10), open('conjuntos.sav', 'wb'))\n",
    "\n",
    "print(\"Archivos guardados correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
